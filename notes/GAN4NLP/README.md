# Generative Adversarial Nets 4 NLP
GAN ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏î‡∏µ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏ö‡∏ö‡πÇ‡∏î‡∏¢‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏á‡∏≤‡∏ô Computer Vision ‡πÅ‡∏ï‡πà‡∏ó‡∏≥‡πÑ‡∏° GAN ‡∏ñ‡∏∂‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏ó‡∏µ‡πà‡∏ô‡∏¥‡∏¢‡∏°‡πÉ‡∏ô NLP ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏°‡∏≤‡∏Ñ‡∏∏‡∏¢‡∏ß‡πà‡∏≤‡∏ó‡∏≥‡πÑ‡∏° GAN ‡∏ñ‡∏∂‡∏á‡∏¢‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡πÉ‡∏ô NLP ‡πÅ‡∏•‡πâ‡∏ß‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏ô‡∏±‡∏Å‡∏ß‡∏¥‡∏à‡∏±‡∏¢‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ô‡∏µ‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡∏¥‡∏ò‡∏µ‡πÉ‡∏î‡∏ö‡πâ‡∏≤‡∏á.    

‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ GAN ‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡∏Ñ‡∏∑‡∏≠ NLP ‡∏Ñ‡∏∑‡∏≠‡∏õ‡∏Å‡∏ï‡∏¥‡πÅ‡∏•‡πâ‡∏ß image ‡∏à‡∏∞‡∏°‡∏µ output ‡πÉ‡∏ô‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞ continuous ‡πÅ‡∏ï‡πà text ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô discrete ‡∏ó‡∏≥‡πÉ‡∏´‡πâ ‡∏î‡∏¥‡∏ü‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ó‡∏≥ backpropagate ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ 

‡πÉ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏°‡∏µ‡∏ß‡∏¥‡∏ò‡∏µ‡∏´‡∏•‡∏±‡∏Å‡πÜ ‡∏≠‡∏¢‡∏π‡πà‡∏™‡∏≤‡∏°‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏î‡∏¥‡∏ü‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÑ‡∏î‡πâ 
* ‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ‡∏Ç‡∏≠‡∏á‡∏û‡∏ß‡∏Å Reinforcement Learning (RL) ‡∏°‡∏≤‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ ‡∏û‡∏ß‡∏Å RL ‡∏°‡∏±‡∏Å‡∏à‡∏∞‡πÄ‡∏à‡∏≠‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏Å‡∏ï‡∏¥ ‡πÅ‡∏ô‡∏ß‡∏Ñ‡∏¥‡∏î‡∏à‡∏≤‡∏Å RL algorithm ‡∏Å‡∏±‡∏ö policy gradients ‡∏à‡∏∞‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ
* [Gumble-softmax approximation](https://arxiv.org/abs/1611.01144) ‡∏ä‡πà‡∏ß‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Ñ‡πà‡∏≤ continous ‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô discrete distribution ‡πÑ‡∏î‡πâ 
* ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á discrete output ‡πÇ‡∏î‡∏¢‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÉ‡∏ä‡πâ continuous output ‡πÅ‡∏ó‡∏ô (‡πÄ‡∏ä‡πà‡∏ô ‡πÉ‡∏ä‡πâ sentence vector ‡πÅ‡∏ó‡∏ô discrete tokens ‡∏´‡∏•‡∏≤‡∏¢‡πÜ‡∏≠‡∏±‡∏ô)

## RL
‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ï‡∏µ‡πÇ‡∏à‡∏ó‡∏¢‡πå text generation ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô RL ‡πÑ‡∏î‡πâ ‡πÇ‡∏î‡∏¢‡∏°‡∏≠‡∏á‡∏ß‡πà‡∏≤ text generation ‡πÄ‡∏õ‡πá‡∏ô state-action sequence ‡πÄ‡∏ä‡πà‡∏ô state (s) ‡∏Ñ‡∏∑‡∏≠ text ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å generated ‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß ‡∏™‡πà‡∏ß‡∏ô action ‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏ñ‡∏±‡∏î‡πÑ‡∏õ ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏≥‡∏à‡∏ô‡∏à‡∏ö (‡πÄ‡∏ä‡πà‡∏ô‡∏à‡∏ö‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ,‡πÄ‡∏à‡∏≠ end of sentence token) ‡∏Å‡πá‡πÉ‡∏´‡πâ‡∏£‡∏≤‡∏á‡∏ß‡∏±‡∏•‡∏ß‡πà‡∏≤ text ‡∏ó‡∏µ‡πà generated ‡∏°‡∏≤‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô ‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Ç‡∏≠‡∏á GAN, discriminator ‡∏à‡∏∞‡∏°‡∏µ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ reward ‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å action ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ state ‡∏Å‡πá‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á policy function <img src="/notes/GAN4NLP/tex/71eaf018b849f00f26091e219e9ef9f0.svg?invert_in_darkmode&sanitize=true" align=middle width=65.38039694999999pt height=24.65753399999998pt/>  ‡πÇ‡∏î‡∏¢ ùúÉ ‡∏Ñ‡∏∑‡∏≠ ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå  ‡∏™‡πà‡∏ß‡∏ô output ‡∏Ñ‡∏∑‡∏≠ distribution ‡∏Ç‡∏≠‡∏á action ‡∏ï‡πà‡∏≤‡∏á‡πÜ (given state). ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏∞ generate text ‡πÇ‡∏î‡∏¢ sample ‡∏à‡∏≤‡∏Å policy            
           
‡∏ñ‡πâ‡∏≤ **J(ùúÉ)** ‡∏Ñ‡∏∑‡∏≠‡∏°‡∏≤‡∏ï‡∏£‡∏ß‡∏±‡∏î performance ‡πÄ‡∏£‡∏≤‡∏Å‡πá‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå **ùúÉ*** ‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ performance ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ö‡∏ô **J(ùúÉ)** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏´‡∏≤ ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå **ùúÉ*** ‡∏ó‡∏µ‡πà maximize performance ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ó‡∏≥ gradient ascent: <img src="/notes/GAN4NLP/tex/2b076affa2b854c435b9ef26b9f6ca35.svg?invert_in_darkmode&sanitize=true" align=middle width=155.79307755pt height=36.56024129999999pt/> ‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ô‡∏µ‡πâ‡∏´‡∏°‡∏ß‡∏Å (^) ‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤ gradient ‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏°‡∏≤ ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ concept ‡∏Ç‡∏≠‡∏á   [policy gradient theorem](https://lilianweng.github.io/lil-log/2018/04/08/policy-gradient-algorithms.html#policy-gradient-theorem): <img src="/notes/GAN4NLP/tex/c48fce8bebc6bb658babfd5ff2ccecc2.svg?invert_in_darkmode&sanitize=true" align=middle width=284.3723025pt height=24.657735299999988pt/>         
          
* **ùúá(s)** ‡∏ß‡∏±‡∏î‡∏ß‡πà‡∏≤ agent ‡∏°‡∏µ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÑ‡∏õ‡∏ó‡∏µ‡πà state **s** ‡∏ö‡πà‡∏≠‡∏¢‡πÅ‡∏Ñ‡πà‡πÑ‡∏´‡∏ô ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡∏Å‡∏ó‡∏≥‡∏ï‡∏≤‡∏° policy **ùúã**
* **q(s, a)** ‡∏ß‡∏±‡∏î‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á action **a** ‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏ô state **s** 

‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ ‡∏™‡∏°‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏≤‡∏ô‡∏Ç‡∏ß‡∏≤‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ö‡∏ß‡∏Å‡∏£‡∏ß‡∏°‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å  action **a** ‡πÅ‡∏•‡∏∞‡∏ó‡∏∏‡∏Å state **s** ‡πÅ‡∏ï‡πà‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏±‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÑ‡∏î‡πâ ‡πÄ‡∏ä‡πà‡∏ô  a ‡∏Å‡∏±‡∏ö s ‡∏ó‡∏µ‡πà timestep t  (s_t,a_t) ‡πÄ‡∏£‡∏≤‡∏à‡∏∂‡∏á‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ REINFORCE algorithm ‡∏°‡∏≤‡∏ä‡πà‡∏ß‡∏¢

‡πÄ‡∏°‡∏∑‡πà‡∏≠  **ùúá(s)** ‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏õ‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà state **s** ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡∏Å‡∏ó‡∏≥‡∏ï‡∏≤‡∏° policy **ùúã**  ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏°‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏ß‡∏Å‡∏£‡∏ß‡∏°‡∏î‡πâ‡∏≤‡∏ô‡∏ô‡∏≠‡∏Å(outer summation)‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô[expected value](https://en.wikipedia.org/wiki/Expected_value)‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏ß‡∏Å‡∏£‡∏ß‡∏°‡∏î‡πâ‡∏≤‡∏ô‡πÉ‡∏ô(inner summation):                   
<img src="/notes/GAN4NLP/tex/5438c2fb90db561dcf0582b8a64a2bdc.svg?invert_in_darkmode&sanitize=true" align=middle width=211.55697584999996pt height=24.657735299999988pt/>            

Note: ‡∏ô‡∏¥‡∏¢‡∏≤‡∏°‡∏Ç‡∏≠‡∏á expected value ‡∏Ç‡∏≠‡∏á X ‡∏Ñ‡∏∑‡∏≠ <img src="/notes/GAN4NLP/tex/d80a6cf59402c36f447decf63e8d5c10.svg?invert_in_darkmode&sanitize=true" align=middle width=327.18282465pt height=32.51169900000002pt/> ‡πÇ‡∏î‡∏¢‡∏ó‡∏µ‡πà p ‡∏Ñ‡∏∑‡∏≠ prob               

‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å state ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (s_t) ‡πÑ‡∏î‡πâ‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏∞‡∏ó‡∏≥‡∏¢‡∏±‡∏á‡πÑ‡∏á‡∏ï‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å action ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÑ‡∏î‡πâ action (a_t)                    
‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏°‡∏ß‡πà‡∏≤ <img src="/notes/GAN4NLP/tex/7dc718cfc361109793ac341baea5a8a5.svg?invert_in_darkmode&sanitize=true" align=middle width=71.67427409999999pt height=24.65753399999998pt/> ‡∏Ñ‡∏∑‡∏≠‡∏ü‡∏±‡∏á‡∏ä‡∏±‡πà‡∏ô‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏à‡∏Å‡πÅ‡∏à‡∏á‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô(probability distribution)‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞action ‡∏ó‡∏µ‡πàstate s_t ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏â‡∏∞‡∏ô‡∏±‡πâ‡∏ô‡πÄ‡∏£‡∏≤‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏Ç‡∏≠‡∏á‡∏°‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏≠‡∏µ‡∏Å ‡πÄ‡∏û‡∏£‡∏≤‡∏∞summation ‡∏Ç‡∏≠‡∏á‡∏°‡∏±‡∏ô‡∏Å‡πá‡∏î‡∏π‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡πÜ expected value ‡πÇ‡∏î‡∏¢‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏Ñ‡∏π‡∏ì‡πÅ‡∏•‡∏∞‡∏´‡∏≤‡∏£‡∏™‡∏°‡∏Å‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢<img src="/notes/GAN4NLP/tex/7dc718cfc361109793ac341baea5a8a5.svg?invert_in_darkmode&sanitize=true" align=middle width=71.67427409999999pt height=24.65753399999998pt/> ‡πÄ‡∏£‡∏≤‡∏Å‡πá‡∏à‡∏∞‡πÑ‡∏î‡πâ:            
<img src="/notes/GAN4NLP/tex/73d7a61c2deba672dbf12f6ca373c70d.svg?invert_in_darkmode&sanitize=true" align=middle width=191.57973779999998pt height=37.80850590000001pt/>

## Reading List
[GAN - NAACL 2019](https://drive.google.com/drive/folders/1E4uHe4_TD4yDJws3t1kXJQanUFJiqpBB)                  
[Generative Adversarial Networks for Text Generation (blog post)](https://becominghuman.ai/generative-adversarial-networks-for-text-generation-part-1-2b886c8cab10)                 
[SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient](https://www.aaai.org/ocs/index.php/AAAI/AAAI17/paper/download/14344/14489)
